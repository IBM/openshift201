{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 OpenShift 201: Learn the integrations of Red Hat OpenShift on IBM Cloud \u00b6 A recent study by McKinsey & Company reveals that only 20 percent of enterprise applications have moved to the cloud. We believe that a hybrid cloud approach, built on open source and a vibrant open ecosystem, is the best way to move the remaining 80 percent. Red Hat OpenShift represents a common platform, based on the industry-standard Kubernetes, that allows you to build on premises, on the IBM Cloud, or on any other leading cloud platform. You want freedom of choice; Red Hat OpenShift offers exactly that. The goals of this workshop are: To familiarize the student with OpenShift on IBM Cloud To learn how to integrate OpenShift and IBM Cloud Architecture \u00b6 A developer generates a starter application with IBM Cloud Developer Tools. Building the application produces a Docker container image. The image is pushed to a project in OpenShift cluster. The application is deployed to a OpenShift cluster. Users access the application. A developer connects the application to a Cloudant database with Operator. A developper monitors the app with LogDNA and Sysdig. Agenda \u00b6 Getting Started \u00b6 Create account and get cluster Access the cluster using the command line OpenShift and IBM Cloud \u00b6 Cloudant DB with IBM Cloud Operator Configure the Sysdig Agent Monitor your Cluster with SysDig Configure the LogDNA Agent Analyze your logs with LogDNA Compatibility \u00b6 This workshop has been tested on the following platforms: macOS : Mojave \\(10.14\\) , Catalina \\(10.15\\) , Chrome \\(79.x\\) Credits \u00b6 Many folks have contributed to help shape, test, and contribute the workshop. Spencer Krum JJ Asghar Tim Robinson Mofi Rahman Sai Vennam Steve Martinelli Ram Vennam Remko De Knikker Alex Parker Lionel Mace Marisa Lopez de Silanes Ruiz","title":"About the workshop"},{"location":"#introduction","text":"","title":"Introduction"},{"location":"#openshift-201-learn-the-integrations-of-red-hat-openshift-on-ibm-cloud","text":"A recent study by McKinsey & Company reveals that only 20 percent of enterprise applications have moved to the cloud. We believe that a hybrid cloud approach, built on open source and a vibrant open ecosystem, is the best way to move the remaining 80 percent. Red Hat OpenShift represents a common platform, based on the industry-standard Kubernetes, that allows you to build on premises, on the IBM Cloud, or on any other leading cloud platform. You want freedom of choice; Red Hat OpenShift offers exactly that. The goals of this workshop are: To familiarize the student with OpenShift on IBM Cloud To learn how to integrate OpenShift and IBM Cloud","title":"OpenShift 201: Learn the integrations of Red Hat OpenShift on IBM Cloud"},{"location":"#architecture","text":"A developer generates a starter application with IBM Cloud Developer Tools. Building the application produces a Docker container image. The image is pushed to a project in OpenShift cluster. The application is deployed to a OpenShift cluster. Users access the application. A developer connects the application to a Cloudant database with Operator. A developper monitors the app with LogDNA and Sysdig.","title":"Architecture"},{"location":"#agenda","text":"","title":"Agenda"},{"location":"#getting-started","text":"Create account and get cluster Access the cluster using the command line","title":"Getting Started"},{"location":"#openshift-and-ibm-cloud","text":"Cloudant DB with IBM Cloud Operator Configure the Sysdig Agent Monitor your Cluster with SysDig Configure the LogDNA Agent Analyze your logs with LogDNA","title":"OpenShift and IBM Cloud"},{"location":"#compatibility","text":"This workshop has been tested on the following platforms: macOS : Mojave \\(10.14\\) , Catalina \\(10.15\\) , Chrome \\(79.x\\)","title":"Compatibility"},{"location":"#credits","text":"Many folks have contributed to help shape, test, and contribute the workshop. Spencer Krum JJ Asghar Tim Robinson Mofi Rahman Sai Vennam Steve Martinelli Ram Vennam Remko De Knikker Alex Parker Lionel Mace Marisa Lopez de Silanes Ruiz","title":"Credits"},{"location":"SUMMARY/","text":"Summary \u00b6 Introduction Getting Started \u00b6 Create Account and Get Cluster Configure Shell Access Workshop \u00b6 Cloudant DB with IBM Cloud Operator Configure the Sysdig Agent Monitor your Cluster with SysDig Configure the LogDNA Agent Analyze your logs with LogDNA Resources \u00b6 Docs: Red Hat OpenShift on IBM Cloud Docs: OpenShift Container Platform 4.3","title":"Summary"},{"location":"SUMMARY/#summary","text":"Introduction","title":"Summary"},{"location":"SUMMARY/#getting-started","text":"Create Account and Get Cluster Configure Shell Access","title":"Getting Started"},{"location":"SUMMARY/#workshop","text":"Cloudant DB with IBM Cloud Operator Configure the Sysdig Agent Monitor your Cluster with SysDig Configure the LogDNA Agent Analyze your logs with LogDNA","title":"Workshop"},{"location":"SUMMARY/#resources","text":"Docs: Red Hat OpenShift on IBM Cloud Docs: OpenShift Container Platform 4.3","title":"Resources"},{"location":"exercise-01/readme/","text":"Cloudant DB with IBM Cloud Operator \u00b6 Currently, the Example Health patient-ui app is using a dummy in-memory patient. In this exercise, you'll create a Cloudant service in IBM Cloud and populate it with patient data. Cloudant is a NoSQL database-as-a-service, based on CouchDB. Enable the IBM Cloud Operator \u00b6 Let's understand exactly how Operators work. In the first exercise, you deployed a simple application using a DeploymentConfig and Pods -- these are \"default resources\" that come with OpenShift. A custom resource definition allows you to create resources that are not necessarily running within Kubernetes, such an IBM Cloud service. Operators manage the lifecycle of resources and create CRDs, allowing you to manage custom resources the native \"Kubernetes\" way. Navigate to your OpenShift console, access the Administrator view, and click Operators > OperatorHub Find the IBM Cloud Operator , and hit Install Keep the default options and hit Subscribe : You may need to wait a few seconds and refresh for the operator to show up as Installed : Next, you'll need to set your IBM Cloud credentials so that the Operator knows how/where to create your Cloudant service. The operator needs to create the service in your own account, rather than the shared IBM lab account. ibmcloud login --sso Remember: Pick your own account, not IBM. Select an account: 1 . Sai Vennam ' s Account ( d815248d6ad0cc354df42d43db45ce09 ) <-> 1909673 2 . IBM ( 3a4766a7bcab032d4ffc980d360fbf23 ) <-> 338150 Enter a number> 1 Next, set your CF org, space and resource group where the Cloudant service will be created. Resource group is usually named default or Default -- case-sensitive. ibmcloud target --cf -g Default or ibmcloud target --cf -g default Verify that all fields are set: ibmcloud target API endpoint: https://cloud.ibm.com Region: us-south User: svennam@us.ibm.com Account: Sai Vennam ' s Account ( d815248d6ad0cc354df42d43db45ce09 ) <-> 1909673 Resource group: default CF API endpoint: https://api.us-south.cf.cloud.ibm.com ( API version: 2 .144.0 ) Org: svennam@us.ibm.com Space: dev If any of these fields are not set, the Operator will fail to create your service! Make sure you're logged in to the cluster in this terminal session. Otherwise you must re-run the command oc login with the cluster information: Access your cluster using the oc CLI . Use the helper script provided by IBM to create a new API token, and register it as a secret in your OpenShift cluster: curl -sL https://raw.githubusercontent.com/IBM/cloud-operators/master/hack/config-operator.sh | bash Verify that all the fields in data are set for the configmap \\( org , region , resourceGroup and space \\) and secret \\( api-key and region \\) : oc get configmap/seed-defaults -o yaml -n default oc get secret/seed-secret -o yaml -n default Output: apiVersion: v1 data: org: svennam@us.ibm.com region: us-south resourceGroup: default space: dev ... apiVersion: v1 data: api-key: <PRIVATE_API_TOKEN> = region: dXMtc291dGg = ... Create a Cloudant Service using the CRDs \u00b6 Once the Operator is installed, the Custom Resource Definitions to create the Cloudant service are also available. Navigate to your OpenShift dashboard, ensure you're in the Administrator view, navigate to your Installed Operators and click the IBM Cloud Operator: You'll see that there's two APIs available -- a Service and a Binding. A Service will allow us to create the actual Cloudant service itself -- do that first by clicking Create Instance under Service . Copy and replace the following YAML: apiVersion : ibmcloud.ibm.com/v1alpha1 kind : Service metadata : name : cloudant-service spec : plan : lite serviceClass : cloudantnosqldb Hit Create . Wait a couple minutes for the service to provision. You can check the status by clicking on your service, and looking for Message: Online : {% hint style='info' %} You can also debug any potential issues here. If you already have a Cloudant \"Lite\" service, you won't be able to create another. To work around this issue, edit the service yaml to use standard instead of lite . Note that \"Standard Cloudant\" is a paid service. Another option is to navigate to your IBM Cloud dashboard and delete your existing instance of the lite Cloudant. {% endhint %} After verifying that there's no bugs and the service is \"online\", double-check that the Cloudant service exists in your account: https://cloud.ibm.com/resources You may need to switch to your own account using the switcher on the top right. Next, create the \"binding\" resource for your Operator \\(instead of Service as you did above\\) : apiVersion: ibmcloud.ibm.com/v1alpha1 kind: Binding metadata: name: cloudant-binding spec: serviceName: cloudant-service The binding should get created fairly quickly -- you can check the status by clicking on your binding, and looking for Message: Online . By navigating to the Resources tab, you can see that the cloudant-binding secret is created. Click that to see your credentials for accessing your Cloudant DB, stored securely in a secret: Deploy the Node.js Patient Database App \u00b6 Now you'll create the Node.js app that will populate your Cloudant DB with patient data. It will also serve data to the front-end application that we deployed in the first exercise. Make sure you're in the project example-health : oc project example-health Run the following command to create this application: oc new-app --name = patient-db centos/nodejs-10-centos7~https://github.com/svennam92/nodejs-patientdb-cloudant The app will crash and fail to start repeatedly because the credentials to the Cloudant DB haven't been set yet. Let's fix this by setting the environment variable to the cloudant-binding secret we created earlier. Navigate to the deployment config for the patient-db app by clicking the app, and then selecting the name next to DC : Go to the Environment tab, click Add from Config Map or Secret and create a new environment variable named CLOUDANT_URL . Choose the cloudant-binding secret, then choose url for the Key. Hit the Save button. Go back to the Topology tab, and the patient-db should successfully start shortly. Configure Front-End Patient Health App to use Cloudant Database Backend \u00b6 The patient-ui application has a configuration option for the backend database. To start using the database you configured above, follow the steps below to configure it. Access your patient-ui application again and click Settings . To find your routes, you can use the OpenShift console or type oc get routes . Input the route http://patient-db:8080/ and hit the node OpenShift icon. You won't need to expose this application with the oc expose command. This is because your frontend patient-ui application can talk to the backend patient-db without the network request leaving the cluster. Kubernetes keeps an internal DNS record of the services which resolve to the IPs of the running application. Your application is now backed by the mock patient data in the Cloudant DB! You can log-in using any user-id/password in the Cloudant DB, for example \" opall:opall \". In a real-world application, these passwords should not be stored as plain-text. To review the patients (and alternate logins) in the Cloudant DB, navigate to your services in IBM Cloud Resource List . Click cloudant-service . Launch the Cloudant dashboard and click the patients db. Click through the different patients you can log-in as.","title":"Cloudant DB with IBM Cloud Operator"},{"location":"exercise-01/readme/#cloudant-db-with-ibm-cloud-operator","text":"Currently, the Example Health patient-ui app is using a dummy in-memory patient. In this exercise, you'll create a Cloudant service in IBM Cloud and populate it with patient data. Cloudant is a NoSQL database-as-a-service, based on CouchDB.","title":"Cloudant DB with IBM Cloud Operator"},{"location":"exercise-01/readme/#enable-the-ibm-cloud-operator","text":"Let's understand exactly how Operators work. In the first exercise, you deployed a simple application using a DeploymentConfig and Pods -- these are \"default resources\" that come with OpenShift. A custom resource definition allows you to create resources that are not necessarily running within Kubernetes, such an IBM Cloud service. Operators manage the lifecycle of resources and create CRDs, allowing you to manage custom resources the native \"Kubernetes\" way. Navigate to your OpenShift console, access the Administrator view, and click Operators > OperatorHub Find the IBM Cloud Operator , and hit Install Keep the default options and hit Subscribe : You may need to wait a few seconds and refresh for the operator to show up as Installed : Next, you'll need to set your IBM Cloud credentials so that the Operator knows how/where to create your Cloudant service. The operator needs to create the service in your own account, rather than the shared IBM lab account. ibmcloud login --sso Remember: Pick your own account, not IBM. Select an account: 1 . Sai Vennam ' s Account ( d815248d6ad0cc354df42d43db45ce09 ) <-> 1909673 2 . IBM ( 3a4766a7bcab032d4ffc980d360fbf23 ) <-> 338150 Enter a number> 1 Next, set your CF org, space and resource group where the Cloudant service will be created. Resource group is usually named default or Default -- case-sensitive. ibmcloud target --cf -g Default or ibmcloud target --cf -g default Verify that all fields are set: ibmcloud target API endpoint: https://cloud.ibm.com Region: us-south User: svennam@us.ibm.com Account: Sai Vennam ' s Account ( d815248d6ad0cc354df42d43db45ce09 ) <-> 1909673 Resource group: default CF API endpoint: https://api.us-south.cf.cloud.ibm.com ( API version: 2 .144.0 ) Org: svennam@us.ibm.com Space: dev If any of these fields are not set, the Operator will fail to create your service! Make sure you're logged in to the cluster in this terminal session. Otherwise you must re-run the command oc login with the cluster information: Access your cluster using the oc CLI . Use the helper script provided by IBM to create a new API token, and register it as a secret in your OpenShift cluster: curl -sL https://raw.githubusercontent.com/IBM/cloud-operators/master/hack/config-operator.sh | bash Verify that all the fields in data are set for the configmap \\( org , region , resourceGroup and space \\) and secret \\( api-key and region \\) : oc get configmap/seed-defaults -o yaml -n default oc get secret/seed-secret -o yaml -n default Output: apiVersion: v1 data: org: svennam@us.ibm.com region: us-south resourceGroup: default space: dev ... apiVersion: v1 data: api-key: <PRIVATE_API_TOKEN> = region: dXMtc291dGg = ...","title":"Enable the IBM Cloud Operator"},{"location":"exercise-01/readme/#create-a-cloudant-service-using-the-crds","text":"Once the Operator is installed, the Custom Resource Definitions to create the Cloudant service are also available. Navigate to your OpenShift dashboard, ensure you're in the Administrator view, navigate to your Installed Operators and click the IBM Cloud Operator: You'll see that there's two APIs available -- a Service and a Binding. A Service will allow us to create the actual Cloudant service itself -- do that first by clicking Create Instance under Service . Copy and replace the following YAML: apiVersion : ibmcloud.ibm.com/v1alpha1 kind : Service metadata : name : cloudant-service spec : plan : lite serviceClass : cloudantnosqldb Hit Create . Wait a couple minutes for the service to provision. You can check the status by clicking on your service, and looking for Message: Online : {% hint style='info' %} You can also debug any potential issues here. If you already have a Cloudant \"Lite\" service, you won't be able to create another. To work around this issue, edit the service yaml to use standard instead of lite . Note that \"Standard Cloudant\" is a paid service. Another option is to navigate to your IBM Cloud dashboard and delete your existing instance of the lite Cloudant. {% endhint %} After verifying that there's no bugs and the service is \"online\", double-check that the Cloudant service exists in your account: https://cloud.ibm.com/resources You may need to switch to your own account using the switcher on the top right. Next, create the \"binding\" resource for your Operator \\(instead of Service as you did above\\) : apiVersion: ibmcloud.ibm.com/v1alpha1 kind: Binding metadata: name: cloudant-binding spec: serviceName: cloudant-service The binding should get created fairly quickly -- you can check the status by clicking on your binding, and looking for Message: Online . By navigating to the Resources tab, you can see that the cloudant-binding secret is created. Click that to see your credentials for accessing your Cloudant DB, stored securely in a secret:","title":"Create a Cloudant Service using the CRDs"},{"location":"exercise-01/readme/#deploy-the-nodejs-patient-database-app","text":"Now you'll create the Node.js app that will populate your Cloudant DB with patient data. It will also serve data to the front-end application that we deployed in the first exercise. Make sure you're in the project example-health : oc project example-health Run the following command to create this application: oc new-app --name = patient-db centos/nodejs-10-centos7~https://github.com/svennam92/nodejs-patientdb-cloudant The app will crash and fail to start repeatedly because the credentials to the Cloudant DB haven't been set yet. Let's fix this by setting the environment variable to the cloudant-binding secret we created earlier. Navigate to the deployment config for the patient-db app by clicking the app, and then selecting the name next to DC : Go to the Environment tab, click Add from Config Map or Secret and create a new environment variable named CLOUDANT_URL . Choose the cloudant-binding secret, then choose url for the Key. Hit the Save button. Go back to the Topology tab, and the patient-db should successfully start shortly.","title":"Deploy the Node.js Patient Database App"},{"location":"exercise-01/readme/#configure-front-end-patient-health-app-to-use-cloudant-database-backend","text":"The patient-ui application has a configuration option for the backend database. To start using the database you configured above, follow the steps below to configure it. Access your patient-ui application again and click Settings . To find your routes, you can use the OpenShift console or type oc get routes . Input the route http://patient-db:8080/ and hit the node OpenShift icon. You won't need to expose this application with the oc expose command. This is because your frontend patient-ui application can talk to the backend patient-db without the network request leaving the cluster. Kubernetes keeps an internal DNS record of the services which resolve to the IPs of the running application. Your application is now backed by the mock patient data in the Cloudant DB! You can log-in using any user-id/password in the Cloudant DB, for example \" opall:opall \". In a real-world application, these passwords should not be stored as plain-text. To review the patients (and alternate logins) in the Cloudant DB, navigate to your services in IBM Cloud Resource List . Click cloudant-service . Launch the Cloudant dashboard and click the patients db. Click through the different patients you can log-in as.","title":"Configure Front-End Patient Health App to use Cloudant Database Backend"},{"location":"exercise-02/readme/","text":"Configure the Sysdig Agent \u00b6 To integrate your monitoring instance with your OpenShift cluster, you must run a script that creates a project and privileged service account for the Sysdig agent. {% hint style='info' %} If you've been invited to a lab account where an instance of Sysdig has already been provisioned and configured, skip the create and deploy steps and go to verify the agent at the bottom. Retrieve your Sysdig instance by looking at the cluster name in the tags attached to the instance. {% endhint %} Create a Sysdig service instance \u00b6 Create an instance of IBM Cloud Monitoring with Sysdig from the catalog: Set the Service name to YOUR_IBM_ID-sysdig . Select the location where your cluster is created. If the location is not in the list, pick the closest region (e.g. us-south). Use the default resource group. Click Create . In the Observability category, under Monitoring , locate the service instance you created. Deploy the Sysdig agent in the cluster \u00b6 On your instance, click Edit sources . Before running the curl command in the next step, make sure you're still logged in to the cluster. Access your cluster using the oc CLI . Select the OpenShift tab and run the curl command next to Public Endpoint The Sysdig agent collects metrics such as the worker node CPU usage, worker node memory usage, HTTP traffic to and from your containers, and data about several infrastructure components. Verify that the Sysdig agent is deployed successfully \u00b6 Verify that the sydig-agent pods on each node have a Running status. Run the following command: oc get pods -n ibm-observe Example output: NAME READY STATUS RESTARTS AGE sysdig-agent-qrbcq 1/1 Running 0 1m sysdig-agent-rhrgz 1/1 Running 0 1m","title":"Configure the Sysdig Agent"},{"location":"exercise-02/readme/#configure-the-sysdig-agent","text":"To integrate your monitoring instance with your OpenShift cluster, you must run a script that creates a project and privileged service account for the Sysdig agent. {% hint style='info' %} If you've been invited to a lab account where an instance of Sysdig has already been provisioned and configured, skip the create and deploy steps and go to verify the agent at the bottom. Retrieve your Sysdig instance by looking at the cluster name in the tags attached to the instance. {% endhint %}","title":"Configure the Sysdig Agent"},{"location":"exercise-02/readme/#create-a-sysdig-service-instance","text":"Create an instance of IBM Cloud Monitoring with Sysdig from the catalog: Set the Service name to YOUR_IBM_ID-sysdig . Select the location where your cluster is created. If the location is not in the list, pick the closest region (e.g. us-south). Use the default resource group. Click Create . In the Observability category, under Monitoring , locate the service instance you created.","title":"Create a Sysdig service instance"},{"location":"exercise-02/readme/#deploy-the-sysdig-agent-in-the-cluster","text":"On your instance, click Edit sources . Before running the curl command in the next step, make sure you're still logged in to the cluster. Access your cluster using the oc CLI . Select the OpenShift tab and run the curl command next to Public Endpoint The Sysdig agent collects metrics such as the worker node CPU usage, worker node memory usage, HTTP traffic to and from your containers, and data about several infrastructure components.","title":"Deploy the Sysdig agent in the cluster"},{"location":"exercise-02/readme/#verify-that-the-sysdig-agent-is-deployed-successfully","text":"Verify that the sydig-agent pods on each node have a Running status. Run the following command: oc get pods -n ibm-observe Example output: NAME READY STATUS RESTARTS AGE sysdig-agent-qrbcq 1/1 Running 0 1m sysdig-agent-rhrgz 1/1 Running 0 1m","title":"Verify that the Sysdig agent is deployed successfully"},{"location":"exercise-03/readme/","text":"Monitor your Cluster with SysDig \u00b6 IBM Cloud Monitoring with Sysdig is a co-branded cloud-native, and container- intelligence management system that you can include as part of your IBM Cloud architecture. Use it to gain operational visibility into the performance and health of your applications, services, and platforms. It offers administrators, DevOps teams, and developers full stack telemetry with advanced features to monitor and troubleshoot performance issues, define alerts, and design custom dashboards. IBM Cloud Monitoring with Sysdig is operated by Sysdig in partnership with IBM. Learn more . In the next steps, you will learn how to use dashboards and metrics to monitor the health of your application. View SysDig pre-defined views and dashboards \u00b6 Use views and dashboards to monitor your infrastructure, applications, and services. You can use pre-defined dashboards. You can also create custom dashboards through the Web UI or programmatically. You can backup and restore dashboards by using Python scripts. The following table lists the different types of pre-defined dashboards: Type Description Applications Dashboards that you can use to monitor your applications and infrastructure components. Host and containers Dashboards that you can use to monitor resource utilization and system activity on your hosts and in your containers. Network Dashboards that you can use to monitor your network connections and activity. Service Dashboards that you can use to monitor the performance of your services, even if those services are deployed in orchestrated containers. Topology Dashboards that you can use to monitor the logical dependencies of your application tiers and overlay metrics. Complete the Sysdig installation wizard \u00b6 Launch the Sysdig web UI. In the Sysdig Welcome wizard, click Next Select Kubernetes | GKE | OpenShift as the installation method. You should see a message You have X agents connected . Click GO TO NEXT STEP . Setup is complete. Click LET'S GET STARTED Select Next Finally Complete Onboarding View the Sysdig dashboard \u00b6 Navigate the Sysdig console to get metrics on your Kubernetes cluster, nodes, deployments, pods, containers. Under the Explore section,select Containerized Apps to view raw metrics for all workloads running on the cluster. Under Explore , select Nodes , search patient-ui . Look for the partientui pod entry. Under Dashboard , select Default Dashboards > Applications . Then select HTTP to get a global view of the cluster HTTP load. Under Dashboard, select Default Dashboards > Hosts & Containers . Then select Overview by Host to understand how nodes are currently performing. Explore the normal traffic flow of the application \u00b6 You can use the Connection Table dashboard to monitor how data flows between your application components. From the Explore tab, select Deployments . Select your cluster (e.g. roks081). Then, select the namespace where you deployed your sample app. Select the patientui pod entry. Select Default Dashboards . Check out the two dashboards under Hosts & Containers : Overview by Host Overview by Container . Explore the cluster and the node capacity \u00b6 From the Explore tab, select Deployments . Select your cluster (e.g. roks081). Then, select the namespace where you deployed your sample app. Select the patientui pod entry. Select Default Dashboards . Select Kubernetes > Kuberentes Cluster and Node Capacity . Check the Total CPU Capacity . This is the CPU capacity that has been reserved for the node including system daemons. Check the Total Allocatable CPU . This is the CPU which is available for pods excluding system daemons. Check the Total Pod CPU limit . It should be less than the allocatable CPU of the node or cluster. Check the Total Pod CPU Requested . It is the amount of CPU that will be guaranteed for pods on the node or cluster. Check the Total Pod CPU Usage . It is the total amount of CPU that is used by all Pods on the node or cluster. Explore the Network \u00b6 From the DASHBOARDS tab, select Default Dashboards . Then, select Network > Overview . The following dashboard is displayed. It shows information about all resources that are monitored thorugh the instance. Change the scope of the dashboard to display information about your openshift cluster. Select Edit scope on the right side and change it: The dashboard now shows information about the ibm-observe namespace. {% hint style='tip' %} Find more about IBM Cloud Monitoring with Sysdig in the IBM Cloud documentation . Thanks so much for running this full workshop, we hope you've learned something. If you can reach out to the TA or Workshop Presenter and say you've completed with any feedback you may have.","title":"Monitor your Cluster with SysDig"},{"location":"exercise-03/readme/#monitor-your-cluster-with-sysdig","text":"IBM Cloud Monitoring with Sysdig is a co-branded cloud-native, and container- intelligence management system that you can include as part of your IBM Cloud architecture. Use it to gain operational visibility into the performance and health of your applications, services, and platforms. It offers administrators, DevOps teams, and developers full stack telemetry with advanced features to monitor and troubleshoot performance issues, define alerts, and design custom dashboards. IBM Cloud Monitoring with Sysdig is operated by Sysdig in partnership with IBM. Learn more . In the next steps, you will learn how to use dashboards and metrics to monitor the health of your application.","title":"Monitor your Cluster with SysDig"},{"location":"exercise-03/readme/#view-sysdig-pre-defined-views-and-dashboards","text":"Use views and dashboards to monitor your infrastructure, applications, and services. You can use pre-defined dashboards. You can also create custom dashboards through the Web UI or programmatically. You can backup and restore dashboards by using Python scripts. The following table lists the different types of pre-defined dashboards: Type Description Applications Dashboards that you can use to monitor your applications and infrastructure components. Host and containers Dashboards that you can use to monitor resource utilization and system activity on your hosts and in your containers. Network Dashboards that you can use to monitor your network connections and activity. Service Dashboards that you can use to monitor the performance of your services, even if those services are deployed in orchestrated containers. Topology Dashboards that you can use to monitor the logical dependencies of your application tiers and overlay metrics.","title":"View SysDig pre-defined views and dashboards"},{"location":"exercise-03/readme/#complete-the-sysdig-installation-wizard","text":"Launch the Sysdig web UI. In the Sysdig Welcome wizard, click Next Select Kubernetes | GKE | OpenShift as the installation method. You should see a message You have X agents connected . Click GO TO NEXT STEP . Setup is complete. Click LET'S GET STARTED Select Next Finally Complete Onboarding","title":"Complete the Sysdig installation wizard"},{"location":"exercise-03/readme/#view-the-sysdig-dashboard","text":"Navigate the Sysdig console to get metrics on your Kubernetes cluster, nodes, deployments, pods, containers. Under the Explore section,select Containerized Apps to view raw metrics for all workloads running on the cluster. Under Explore , select Nodes , search patient-ui . Look for the partientui pod entry. Under Dashboard , select Default Dashboards > Applications . Then select HTTP to get a global view of the cluster HTTP load. Under Dashboard, select Default Dashboards > Hosts & Containers . Then select Overview by Host to understand how nodes are currently performing.","title":"View the Sysdig dashboard"},{"location":"exercise-03/readme/#explore-the-normal-traffic-flow-of-the-application","text":"You can use the Connection Table dashboard to monitor how data flows between your application components. From the Explore tab, select Deployments . Select your cluster (e.g. roks081). Then, select the namespace where you deployed your sample app. Select the patientui pod entry. Select Default Dashboards . Check out the two dashboards under Hosts & Containers : Overview by Host Overview by Container .","title":"Explore the normal traffic flow of the application"},{"location":"exercise-03/readme/#explore-the-cluster-and-the-node-capacity","text":"From the Explore tab, select Deployments . Select your cluster (e.g. roks081). Then, select the namespace where you deployed your sample app. Select the patientui pod entry. Select Default Dashboards . Select Kubernetes > Kuberentes Cluster and Node Capacity . Check the Total CPU Capacity . This is the CPU capacity that has been reserved for the node including system daemons. Check the Total Allocatable CPU . This is the CPU which is available for pods excluding system daemons. Check the Total Pod CPU limit . It should be less than the allocatable CPU of the node or cluster. Check the Total Pod CPU Requested . It is the amount of CPU that will be guaranteed for pods on the node or cluster. Check the Total Pod CPU Usage . It is the total amount of CPU that is used by all Pods on the node or cluster.","title":"Explore the cluster and the node capacity"},{"location":"exercise-03/readme/#explore-the-network","text":"From the DASHBOARDS tab, select Default Dashboards . Then, select Network > Overview . The following dashboard is displayed. It shows information about all resources that are monitored thorugh the instance. Change the scope of the dashboard to display information about your openshift cluster. Select Edit scope on the right side and change it: The dashboard now shows information about the ibm-observe namespace. {% hint style='tip' %} Find more about IBM Cloud Monitoring with Sysdig in the IBM Cloud documentation . Thanks so much for running this full workshop, we hope you've learned something. If you can reach out to the TA or Workshop Presenter and say you've completed with any feedback you may have.","title":"Explore the Network"},{"location":"exercise-04/readme/","text":"Configure LogDNA agent for OpenShift cluster \u00b6 The LogDNA agent is responsible for collecting and forwarding logs to your IBM Log Analysis with LogDNA instance. After you provision an instance of IBM Log Analysis with LogDNA, you must configure a LogDNA agent for each log source that you want to monitor. To configure your Kubernetes cluster to send logs to your IBM Log Analysis with LogDNA instance, you must install a LogDNA-agent pod on each node of your cluster. The LogDNA agent reads log files from the pod where it is installed, and forwards the log data to your LogDNA instance. {% hint style='info' %} If you've been invited to a lab account where an instance of LogDNA has already been provisioned and configured, skip the create and deploy steps and go to verify the agent at the bottom. Retrieve your LogDNA instance be looking at the cluster name in the tags attached to the instance. {% endhint %} Create a LogDNA service instance \u00b6 Create an instance of IBM Cloud Logging with LogDNA from the catalog: Set the Service name to YOUR_IBM_ID-logdna . Select the location where your cluster is created. If the location is not in the list, pick the closest region (e.g. us-south). Use the default resource group. Click Create . In the Observability category, under Logging , locate the service instance you created. Deploy the LogDNA agent in the cluster \u00b6 On your instance, click Edit log sources . Before running the curl command in the next step, make sure you're still logged in to the cluster. Access your cluster using the oc CLI . Select the OpenShift tab and run the 5 steps command: The LogDNA agent collects logs with the extension *.log and extensionsless files that are stored in the /var/log directory of your pod. By default, logs are collected from all namespaces, including kube-system , and automatically forwarded to the IBM Log Analysis with LogDNA service. Verify that the LogDNA agent is deployed successfully \u00b6 To verify that the LogDNA agent is deployed successfully, run the following command: Target the project where the LogDNA agent is deployed. oc project ibm-observe Verify that the logdna-agent pods on each node are in a Running status. oc get pods -n ibm-observe The deployment is successful when you see one or more LogDNA pods. * The number of LogDNA pods equals the number of worker nodes in your cluster. * All pods must be in a Running state. * Stdout and stderr are automatically collected and forwarded from all containers. Log data includes application logs and worker logs. * By default, the LogDNA agent pod that runs on a worker collects logs from all namespaces on that node. After the agent is configured, you should start seeing logs from this cluster in the LogDNA web UI. If after a period of time you cannot see logs, check the agent logs. To check the logs that are generated by a LogDNA agent, run the following command: oc logs logdna-agent-<ID> Where ID is the ID for a LogDNA agent pod. For example, oc logs logdna-agent-xxxkz","title":"Configure the LogDNA Agent"},{"location":"exercise-04/readme/#configure-logdna-agent-for-openshift-cluster","text":"The LogDNA agent is responsible for collecting and forwarding logs to your IBM Log Analysis with LogDNA instance. After you provision an instance of IBM Log Analysis with LogDNA, you must configure a LogDNA agent for each log source that you want to monitor. To configure your Kubernetes cluster to send logs to your IBM Log Analysis with LogDNA instance, you must install a LogDNA-agent pod on each node of your cluster. The LogDNA agent reads log files from the pod where it is installed, and forwards the log data to your LogDNA instance. {% hint style='info' %} If you've been invited to a lab account where an instance of LogDNA has already been provisioned and configured, skip the create and deploy steps and go to verify the agent at the bottom. Retrieve your LogDNA instance be looking at the cluster name in the tags attached to the instance. {% endhint %}","title":"Configure LogDNA agent for OpenShift  cluster"},{"location":"exercise-04/readme/#create-a-logdna-service-instance","text":"Create an instance of IBM Cloud Logging with LogDNA from the catalog: Set the Service name to YOUR_IBM_ID-logdna . Select the location where your cluster is created. If the location is not in the list, pick the closest region (e.g. us-south). Use the default resource group. Click Create . In the Observability category, under Logging , locate the service instance you created.","title":"Create a LogDNA service instance"},{"location":"exercise-04/readme/#deploy-the-logdna-agent-in-the-cluster","text":"On your instance, click Edit log sources . Before running the curl command in the next step, make sure you're still logged in to the cluster. Access your cluster using the oc CLI . Select the OpenShift tab and run the 5 steps command: The LogDNA agent collects logs with the extension *.log and extensionsless files that are stored in the /var/log directory of your pod. By default, logs are collected from all namespaces, including kube-system , and automatically forwarded to the IBM Log Analysis with LogDNA service.","title":"Deploy the LogDNA agent in the cluster"},{"location":"exercise-04/readme/#verify-that-the-logdna-agent-is-deployed-successfully","text":"To verify that the LogDNA agent is deployed successfully, run the following command: Target the project where the LogDNA agent is deployed. oc project ibm-observe Verify that the logdna-agent pods on each node are in a Running status. oc get pods -n ibm-observe The deployment is successful when you see one or more LogDNA pods. * The number of LogDNA pods equals the number of worker nodes in your cluster. * All pods must be in a Running state. * Stdout and stderr are automatically collected and forwarded from all containers. Log data includes application logs and worker logs. * By default, the LogDNA agent pod that runs on a worker collects logs from all namespaces on that node. After the agent is configured, you should start seeing logs from this cluster in the LogDNA web UI. If after a period of time you cannot see logs, check the agent logs. To check the logs that are generated by a LogDNA agent, run the following command: oc logs logdna-agent-<ID> Where ID is the ID for a LogDNA agent pod. For example, oc logs logdna-agent-xxxkz","title":"Verify that the LogDNA agent is deployed successfully"},{"location":"exercise-05/readme/","text":"Analyze your logs with LogDNA \u00b6 IBM Log Analysis with LogDNA is a co-branded service that you can include as part of your IBM Cloud architecture to add log management capabilities. IBM Log Analysis with LogDNA is operated by LogDNA in partnership with IBM. Learn more . You can use IBM Log Analysis with LogDNA to manage system and application logs in IBM Cloud. {% hint style='info' %} IMPORTANT: Use Chrome to complete this exercise. {% endhint %} Launch the LogDNA webUI \u00b6 You launch the web UI within the context of an IBM Log Analysis with LogDNA instance, from the IBM Cloud UI. Select your instance. Click View LogDNA . The Web UI opens. Create a custom view \u00b6 In LogDNA, you can configure custom views to monitor a subset of data. You can also attach an alert to a view to be notified of the presence or absence of log lines. When you launch the LogDNA web UI, log entries are displayed with a predefined format. You can modify in the User Preferences section how the information in each log line is displayed. You can also filter logs and modify search settings, then bookmark the result as a view . You can attach and detach one or more alerts to a view. You can define a custom format for how your lines are shown in the view. You can expand a log line and see the data parsed. View events with the default format \u00b6 In the LogDNA web UI, click the Views icon . Select Everything to see all the events. Customize your default view \u00b6 In the USER PREFERENCES section, you can modify the order of the data fields that are displayed per line. Select the Configuration icon . Select USER PREFERENCES . A new window opens. Select Log Format . Modify the Line Format section to match your requirements. Drag boxes around. Click Done . For example, add %app after the timestamp. Create a custom view to monitor logs \u00b6 You can select the events that are displayed through a view by applying a search query in the search bar, selecting values in the search area, or a combination of both. You can save that view for reuse later. In the LogDNA web UI, filter out the logs for the sample app that you have delpoyed in the cluster in previous steps. From the Openshift console, go to the developer view. Select the project where you have deployed the sample app, and get the pod name. For example: patient-ui-8658f89574-rgjw8 Enter in the search bar the following query: host:{podName} where {podName} is the name of your pod. For example: host:patient-ui-8658f89574-rgjw8 Click enter. Filter out log lines to display only lines that are tagged as debug lines. Add in the search bar the following query: level:debug and click enter. The view will show lines that meet the filter and search criteria. For example: host:patient-ui-8658f89574-rgjw8 level:debug Save the custom view. Click Unsaved view . Select Save view . Enter the name of the view. Use the following format: <Enter your user name> patientUI . For example, marisa patientui Enter a category. Use the following format: <Enter your user name> . For example, marisa Then click Add new category . Click Save view . A new category appears on the left navigation panel. Generate application log data \u00b6 Generate logs: Run oc status . Get the application URL. Launch the application from a browser. Enter in the browser the application URL. Then, log in and log out with different names to see login entries for each user. Analyze a log line \u00b6 At any time, you can view each log line in context. Complete the following steps: Click the Views icon . Select Everything or a view. Identify a line in the log that you want to explore. Expand the log line. Information about line identifiers, tags, and labels is displayed. Click View in Context to see the log line in context of other log lines from that host, app, or both. This is a very useful feature when you want to troubleshoot a problem. A new pop up window opens. Choose one of the following options: By Everything to see the log line in the context of all log records \\(everything\\) that are available in the LogDNA instance. By source to see the log line in the context of the log lines for the same source. By App to see the log line in the context of the log lines of the app. By Source and App to see the log line in the combined context of the app and source. Then click Continue in New Viewer to get the view in a different page. You might need to scroll down to get this option. Tip: Open a view per type of context to troubleshoot problems. Click Copy to clipboard to copy the message field to the clipboard. For example, the log record in the UI looks like: When you copy the record, you get: [2020-01-16T13:22:25.951] [DEBUG] default - called the information endpoint for Marisa Notice that when you copy the log record you get less information than what it is displayed in the view. To get a line with all the fields, you must export data from a custom view. When you are finished, close the line. View a subset of the events by applying a timeframe \u00b6 In a view, you can search events that are displayed through a view for a specific timeframe. You can apply a timestamp by specifying an absolute time, a relative time, or a time range. Complete the following steps to jump to a specific time: Launch the LogDNA web UI. Click the Views icon. Select your custom view. Enter a time query. Choose any of the following options: Enter an absolute time to jump to a point in time in your events such as January 27 10:00am . Enter a relative time such as 5 days ago . You can also enter a time range such as yesterday 10am to yesterday 11am , last fri 4:30pm to 11/12 1 AM , last wed 4:30pm to 23/05 1 AM , or May 20 10am to May 22 10am . Make sure to include to to separate the initial timestamp from the end timestamp. Click ENTER . You might get the error message: Your request is taking longer than expected, try refreshing your browser in a bit as we try to catch up. Retry. You might get this error when the timeframe that you have specified does not have any events available to show. Change the time query, and retry. Create a dashboard \u00b6 You can create a dashboard to monitor your app graphically through interactive graphs. For example, you can use graphs to analyze patterns and trends over a period of time. Complete the following steps to create a dashboard to monitor logs from the lab's sample app: In the LogDNA web UI, click the Boards icon . Select NEW BOARD to create a new dashboard. Click Add graph . Select the field host , then select the value that matches your pod name. Click Add graph . Open a view that displays the logs for the patientui app. Click the graph in a peak of data at the time that you want to see logs, and then click Show logs . A new page opens with the relevant log entries. Add subplots to analyze the data by applying additonal filtering criteria. Click Show subplots . Select Histogram and level . Name the dashboard by hitting \"Edit\". Enter patientui as the name of the dashboard. Enter a category. Use the following format: <Enter your user name> For example, marisa Then click Add new category . Click Save . A new category appears on the left navigation panel. Create a screen to monitor your app \u00b6 You can create a screen to monitor your app graphically through metrics \\(counters\\) , operational KPIs \\(gauges\\) , tables, and time-shifted graphs \\(graphs that you can use to analyze patterns and trends for comparison analysis\\) . Complete the following steps to create a dashboard to monitor logs from the lab's sample app: In the LogDNA web UI, click the screens icon Select NEW SCREEN . Click Add Widget and select Count . Click the widget. You will get the configuration fields for this widget. To configure the Count widget to report on the log lines for the application patientui, you must select the field app , and set the value to patientui . You can also add a label, by entering a value for the label field -- for example App PatientUI The widget should look similar to the following one: Add a gauge. Click Add Widget . Select Gauge . Click the widget. You will get the configuration fields for this widget. To configure the Gauge widget to report on the debug log lines for the application patientui, you must select the field level , and set the value to debug . Then, set the advanced condition app:patientui . The duration is set to the default, last 1 day. Add a label, by entering a value for the label field. Enter PatientUI - INFO . Also add the gauge limits 0 for Minimum and 5000 for maximum. The widget should look similar to the following one: Add a table. Click Add Widget . Select Table . Click the widget. You will get the configuration fields for this widget. To list the number of records in the last 24 hours for the cluster namespaces, set Group By to namespace . Change the default number of rows from 3 to 10. The widget should look similar to the following one: Save the screen. Select Save Screen . IMPORTANT: If you do not save the screen, you lose all your widgets. {% hint style='tip' %} Find more about IBM Log Analysis with LogDNA in the IBM Cloud documentation .","title":"Analyze your logs with LogDNA"},{"location":"exercise-05/readme/#analyze-your-logs-with-logdna","text":"IBM Log Analysis with LogDNA is a co-branded service that you can include as part of your IBM Cloud architecture to add log management capabilities. IBM Log Analysis with LogDNA is operated by LogDNA in partnership with IBM. Learn more . You can use IBM Log Analysis with LogDNA to manage system and application logs in IBM Cloud. {% hint style='info' %} IMPORTANT: Use Chrome to complete this exercise. {% endhint %}","title":"Analyze your logs with LogDNA"},{"location":"exercise-05/readme/#launch-the-logdna-webui","text":"You launch the web UI within the context of an IBM Log Analysis with LogDNA instance, from the IBM Cloud UI. Select your instance. Click View LogDNA . The Web UI opens.","title":"Launch the LogDNA webUI"},{"location":"exercise-05/readme/#create-a-custom-view","text":"In LogDNA, you can configure custom views to monitor a subset of data. You can also attach an alert to a view to be notified of the presence or absence of log lines. When you launch the LogDNA web UI, log entries are displayed with a predefined format. You can modify in the User Preferences section how the information in each log line is displayed. You can also filter logs and modify search settings, then bookmark the result as a view . You can attach and detach one or more alerts to a view. You can define a custom format for how your lines are shown in the view. You can expand a log line and see the data parsed.","title":"Create a custom view"},{"location":"exercise-05/readme/#view-events-with-the-default-format","text":"In the LogDNA web UI, click the Views icon . Select Everything to see all the events.","title":"View events with the default format"},{"location":"exercise-05/readme/#customize-your-default-view","text":"In the USER PREFERENCES section, you can modify the order of the data fields that are displayed per line. Select the Configuration icon . Select USER PREFERENCES . A new window opens. Select Log Format . Modify the Line Format section to match your requirements. Drag boxes around. Click Done . For example, add %app after the timestamp.","title":"Customize your default view"},{"location":"exercise-05/readme/#create-a-custom-view-to-monitor-logs","text":"You can select the events that are displayed through a view by applying a search query in the search bar, selecting values in the search area, or a combination of both. You can save that view for reuse later. In the LogDNA web UI, filter out the logs for the sample app that you have delpoyed in the cluster in previous steps. From the Openshift console, go to the developer view. Select the project where you have deployed the sample app, and get the pod name. For example: patient-ui-8658f89574-rgjw8 Enter in the search bar the following query: host:{podName} where {podName} is the name of your pod. For example: host:patient-ui-8658f89574-rgjw8 Click enter. Filter out log lines to display only lines that are tagged as debug lines. Add in the search bar the following query: level:debug and click enter. The view will show lines that meet the filter and search criteria. For example: host:patient-ui-8658f89574-rgjw8 level:debug Save the custom view. Click Unsaved view . Select Save view . Enter the name of the view. Use the following format: <Enter your user name> patientUI . For example, marisa patientui Enter a category. Use the following format: <Enter your user name> . For example, marisa Then click Add new category . Click Save view . A new category appears on the left navigation panel.","title":"Create a custom view to monitor logs"},{"location":"exercise-05/readme/#generate-application-log-data","text":"Generate logs: Run oc status . Get the application URL. Launch the application from a browser. Enter in the browser the application URL. Then, log in and log out with different names to see login entries for each user.","title":"Generate application log data"},{"location":"exercise-05/readme/#analyze-a-log-line","text":"At any time, you can view each log line in context. Complete the following steps: Click the Views icon . Select Everything or a view. Identify a line in the log that you want to explore. Expand the log line. Information about line identifiers, tags, and labels is displayed. Click View in Context to see the log line in context of other log lines from that host, app, or both. This is a very useful feature when you want to troubleshoot a problem. A new pop up window opens. Choose one of the following options: By Everything to see the log line in the context of all log records \\(everything\\) that are available in the LogDNA instance. By source to see the log line in the context of the log lines for the same source. By App to see the log line in the context of the log lines of the app. By Source and App to see the log line in the combined context of the app and source. Then click Continue in New Viewer to get the view in a different page. You might need to scroll down to get this option. Tip: Open a view per type of context to troubleshoot problems. Click Copy to clipboard to copy the message field to the clipboard. For example, the log record in the UI looks like: When you copy the record, you get: [2020-01-16T13:22:25.951] [DEBUG] default - called the information endpoint for Marisa Notice that when you copy the log record you get less information than what it is displayed in the view. To get a line with all the fields, you must export data from a custom view. When you are finished, close the line.","title":"Analyze a log line"},{"location":"exercise-05/readme/#view-a-subset-of-the-events-by-applying-a-timeframe","text":"In a view, you can search events that are displayed through a view for a specific timeframe. You can apply a timestamp by specifying an absolute time, a relative time, or a time range. Complete the following steps to jump to a specific time: Launch the LogDNA web UI. Click the Views icon. Select your custom view. Enter a time query. Choose any of the following options: Enter an absolute time to jump to a point in time in your events such as January 27 10:00am . Enter a relative time such as 5 days ago . You can also enter a time range such as yesterday 10am to yesterday 11am , last fri 4:30pm to 11/12 1 AM , last wed 4:30pm to 23/05 1 AM , or May 20 10am to May 22 10am . Make sure to include to to separate the initial timestamp from the end timestamp. Click ENTER . You might get the error message: Your request is taking longer than expected, try refreshing your browser in a bit as we try to catch up. Retry. You might get this error when the timeframe that you have specified does not have any events available to show. Change the time query, and retry.","title":"View a subset of the events by applying a timeframe"},{"location":"exercise-05/readme/#create-a-dashboard","text":"You can create a dashboard to monitor your app graphically through interactive graphs. For example, you can use graphs to analyze patterns and trends over a period of time. Complete the following steps to create a dashboard to monitor logs from the lab's sample app: In the LogDNA web UI, click the Boards icon . Select NEW BOARD to create a new dashboard. Click Add graph . Select the field host , then select the value that matches your pod name. Click Add graph . Open a view that displays the logs for the patientui app. Click the graph in a peak of data at the time that you want to see logs, and then click Show logs . A new page opens with the relevant log entries. Add subplots to analyze the data by applying additonal filtering criteria. Click Show subplots . Select Histogram and level . Name the dashboard by hitting \"Edit\". Enter patientui as the name of the dashboard. Enter a category. Use the following format: <Enter your user name> For example, marisa Then click Add new category . Click Save . A new category appears on the left navigation panel.","title":"Create a dashboard"},{"location":"exercise-05/readme/#create-a-screen-to-monitor-your-app","text":"You can create a screen to monitor your app graphically through metrics \\(counters\\) , operational KPIs \\(gauges\\) , tables, and time-shifted graphs \\(graphs that you can use to analyze patterns and trends for comparison analysis\\) . Complete the following steps to create a dashboard to monitor logs from the lab's sample app: In the LogDNA web UI, click the screens icon Select NEW SCREEN . Click Add Widget and select Count . Click the widget. You will get the configuration fields for this widget. To configure the Count widget to report on the log lines for the application patientui, you must select the field app , and set the value to patientui . You can also add a label, by entering a value for the label field -- for example App PatientUI The widget should look similar to the following one: Add a gauge. Click Add Widget . Select Gauge . Click the widget. You will get the configuration fields for this widget. To configure the Gauge widget to report on the debug log lines for the application patientui, you must select the field level , and set the value to debug . Then, set the advanced condition app:patientui . The duration is set to the default, last 1 day. Add a label, by entering a value for the label field. Enter PatientUI - INFO . Also add the gauge limits 0 for Minimum and 5000 for maximum. The widget should look similar to the following one: Add a table. Click Add Widget . Select Table . Click the widget. You will get the configuration fields for this widget. To list the number of records in the last 24 hours for the cluster namespaces, set Group By to namespace . Change the default number of rows from 3 to 10. The widget should look similar to the following one: Save the screen. Select Save Screen . IMPORTANT: If you do not save the screen, you lose all your widgets. {% hint style='tip' %} Find more about IBM Log Analysis with LogDNA in the IBM Cloud documentation .","title":"Create a screen to monitor your app"},{"location":"pre-work/get_started/","text":"Create account and get cluster \u00b6 In this section, you will login to your own IBM Cloud account, and then get access to a IBM Cloud Lab account which contains pre-provisioned clusters. Each lab attendee will be granted access to one cluster. Set up your IBM Cloud ID \u00b6 Log into IBM Cloud with an existing account: https://cloud.ibm.com OR Create your own: http://cloud.ibm.com/registration Access the Cluster using the Console \u00b6 Instructors will provide a URL to a web app. Enter your IBMid \\(the email you used to sign up\\) and the lab key \\(also provided by the instructor\\) . Follow the instructions on the next page. You will be added to the IBM Workshop account and granted access to a cluster. Note the name of your cluster. In the example below, it's roks07 . Back in IBM Cloud, refresh the IBM Cloud Dashboard . If required, switch to the 1860103 - IBM account by clicking on the account selection drop down in the top nav bar. Click on Clusters in the Resource Summary tile. Under Clusters , click on the cluster that has been assigned to you. You can also see your cluster in the list of OpenShift clusters IBM Cloud Clusters Dashboard Have a look at the cluster overview! Click on OpenShift web console on the top right to launch the web console.","title":"Create Account and Get Cluster"},{"location":"pre-work/get_started/#create-account-and-get-cluster","text":"In this section, you will login to your own IBM Cloud account, and then get access to a IBM Cloud Lab account which contains pre-provisioned clusters. Each lab attendee will be granted access to one cluster.","title":"Create account and get cluster"},{"location":"pre-work/get_started/#set-up-your-ibm-cloud-id","text":"Log into IBM Cloud with an existing account: https://cloud.ibm.com OR Create your own: http://cloud.ibm.com/registration","title":"Set up your IBM Cloud ID"},{"location":"pre-work/get_started/#access-the-cluster-using-the-console","text":"Instructors will provide a URL to a web app. Enter your IBMid \\(the email you used to sign up\\) and the lab key \\(also provided by the instructor\\) . Follow the instructions on the next page. You will be added to the IBM Workshop account and granted access to a cluster. Note the name of your cluster. In the example below, it's roks07 . Back in IBM Cloud, refresh the IBM Cloud Dashboard . If required, switch to the 1860103 - IBM account by clicking on the account selection drop down in the top nav bar. Click on Clusters in the Resource Summary tile. Under Clusters , click on the cluster that has been assigned to you. You can also see your cluster in the list of OpenShift clusters IBM Cloud Clusters Dashboard Have a look at the cluster overview! Click on OpenShift web console on the top right to launch the web console.","title":"Access the Cluster using the Console"},{"location":"pre-work/setup_cli/","text":"Access the cluster using the command line (CLI) \u00b6 To easily connect to the cluster, you need the OpenShift CLI oc that exposes commands for managing your applications, as well as lower level tools to interact with each component of your system. This topic guides you through getting started with the CLI, including installation and logging in. Use IBM Cloud Shell \u00b6 To avoid installing the command line, the recommended approach is to use the IBM Cloud Shell is a cloud-based shell workspace that you can access through your browser. It's preconfigured with the full IBM Cloud CLI and tons of plug-ins and tools that you can use to manage apps, resources, and infrastructure. In the Console menu bar, click the IBM Cloud Shell icon to start a session A session starts and automatically logs you in through the IBM Cloud CLI. Connect to the OpenShift cluster \u00b6 In the OpenShift web console, click on the email/ID in the upper right. Choose the Copy Login Command option. In a Shell termimal, paste the login command you copied from the web console. oc login https://c100-e.us-south.containers.cloud.ibm.com:30360 --token = NYVkVysxxxxxxxxxxxxxxxxxxxxRQa8tM You should see a success message similar to the one below: oc login https://c100-e.us-south.containers.cloud.ibm.com:30360 --token = NYVkVysxxxxxxxxxxxxxxxxxxxxRQa8tM Logged into \"https://c100-e.us-south.containers.cloud.ibm.com:30360\" as \"IAM#firstname.lasname@ibm.com\" using the token provided. You have access to the following projects and can switch between them with 'oc project <projectname>' Your CLI is now connected to your Red Hat OpenShift cluster running in IBM Cloud. Validate cluster access using oc commands \u00b6 View nodes in the cluster. oc get node View services, deployments, and pods. oc get svc,deploy,po --all-namespaces View projects oc get projects You've completed the getting started! Let's recap -- in this section, you: Got an OpenShift cluster and accessed its Web Console. Connected your local CLI to a running OpenShift cluster on IBM Cloud Install OpenShift CLI tools (Optional) \u00b6 The oc CLI will be the main mechanism to interact with your OpenShift cluster. We'll be downloading and installing the CLI, and adding it to your environment path. NOTE : Check for newer releases on the OpenShift Origin Releases page. Download the oc tarball. wget https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz Unpack the tarball tar -xvzf openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz Rename it for ease of use mv openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit ${ HOME } /oc-cli Update PATH . NOTE : If you restart your cloud shell, you may need to re-run this command. export PATH = ${ PATH } : ${ HOME } /oc-cli Verify the utility is available by using which and the help command. which oc oc help","title":"Configure Shell Access"},{"location":"pre-work/setup_cli/#access-the-cluster-using-the-command-line-cli","text":"To easily connect to the cluster, you need the OpenShift CLI oc that exposes commands for managing your applications, as well as lower level tools to interact with each component of your system. This topic guides you through getting started with the CLI, including installation and logging in.","title":"Access the cluster using the command line (CLI)"},{"location":"pre-work/setup_cli/#use-ibm-cloud-shell","text":"To avoid installing the command line, the recommended approach is to use the IBM Cloud Shell is a cloud-based shell workspace that you can access through your browser. It's preconfigured with the full IBM Cloud CLI and tons of plug-ins and tools that you can use to manage apps, resources, and infrastructure. In the Console menu bar, click the IBM Cloud Shell icon to start a session A session starts and automatically logs you in through the IBM Cloud CLI.","title":"Use IBM Cloud Shell"},{"location":"pre-work/setup_cli/#connect-to-the-openshift-cluster","text":"In the OpenShift web console, click on the email/ID in the upper right. Choose the Copy Login Command option. In a Shell termimal, paste the login command you copied from the web console. oc login https://c100-e.us-south.containers.cloud.ibm.com:30360 --token = NYVkVysxxxxxxxxxxxxxxxxxxxxRQa8tM You should see a success message similar to the one below: oc login https://c100-e.us-south.containers.cloud.ibm.com:30360 --token = NYVkVysxxxxxxxxxxxxxxxxxxxxRQa8tM Logged into \"https://c100-e.us-south.containers.cloud.ibm.com:30360\" as \"IAM#firstname.lasname@ibm.com\" using the token provided. You have access to the following projects and can switch between them with 'oc project <projectname>' Your CLI is now connected to your Red Hat OpenShift cluster running in IBM Cloud.","title":"Connect to the OpenShift cluster"},{"location":"pre-work/setup_cli/#validate-cluster-access-using-oc-commands","text":"View nodes in the cluster. oc get node View services, deployments, and pods. oc get svc,deploy,po --all-namespaces View projects oc get projects You've completed the getting started! Let's recap -- in this section, you: Got an OpenShift cluster and accessed its Web Console. Connected your local CLI to a running OpenShift cluster on IBM Cloud","title":"Validate cluster access using oc commands"},{"location":"pre-work/setup_cli/#install-openshift-cli-tools-optional","text":"The oc CLI will be the main mechanism to interact with your OpenShift cluster. We'll be downloading and installing the CLI, and adding it to your environment path. NOTE : Check for newer releases on the OpenShift Origin Releases page. Download the oc tarball. wget https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz Unpack the tarball tar -xvzf openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz Rename it for ease of use mv openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit ${ HOME } /oc-cli Update PATH . NOTE : If you restart your cloud shell, you may need to re-run this command. export PATH = ${ PATH } : ${ HOME } /oc-cli Verify the utility is available by using which and the help command. which oc oc help","title":"Install OpenShift CLI tools (Optional)"},{"location":"resources/","text":"Additional resources \u00b6 IBM Demos \u00b6 Docs: Red Hat OpenShift on IBM Cloud Docs: OpenShift Container Platform 4.3","title":"Additional resources"},{"location":"resources/#additional-resources","text":"","title":"Additional resources"},{"location":"resources/#ibm-demos","text":"Docs: Red Hat OpenShift on IBM Cloud Docs: OpenShift Container Platform 4.3","title":"IBM Demos"}]}